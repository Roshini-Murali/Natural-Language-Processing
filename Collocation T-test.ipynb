{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712149c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'language', 'is', 'filled', 'with', 'ambiguities', 'that', 'make', 'it', 'incredibly', 'difficult', 'to', 'write', 'software', 'that', 'accurately', 'determines', 'the', 'intended', 'meaning', 'of', 'text', 'or', 'voice', 'data', 'homonyms', 'homophones', 'sarcasm', 'idioms', 'metaphors', 'grammar', 'and', 'usage', 'exceptions', 'variations', 'in', 'sentence', 'just', 'a', 'few', 'of', 'the', 'irregularities', 'of', 'human', 'language', 'that', 'take', 'humans', 'years', 'to', 'learn', 'but', 'that', 'programmers', 'must', 'teach', 'natural', 'applications', 'to', 'recognize', 'and', 'understand', 'accurately', 'from', 'the', 'start', 'if', 'those', 'applications', 'are', 'going', 'to', 'be', 'useful', 'several', 'nlp', 'tasks', 'break', 'down', 'human', 'text', 'and', 'voice', 'data', 'in', 'ways', 'that', 'help', 'the', 'computer', 'make', 'sense', 'of', 'what', 'it', 'ingesting', 'some', 'of', 'these', 'tasks', 'include', 'the', 'following', 'speech', 'recognition', 'also', 'called', 'is', 'the', 'task', 'of', 'reliably', 'converting', 'voice', 'data', 'into', 'text', 'data', 'speech', 'recognition', 'is', 'required', 'for', 'any', 'application', 'that', 'follows', 'voice', 'commands', 'or', 'answers', 'spoken', 'questions', 'what', 'makes', 'speech', 'recognition', 'especially', 'challenging', 'is', 'the', 'way', 'people', 'slurring', 'words', 'together', 'with', 'varying', 'emphasis', 'and', 'intonation', 'in', 'different', 'accents', 'and', 'often', 'using', 'incorrect', 'grammar', 'part', 'of', 'speech', 'tagging', 'also', 'called', 'grammatical', 'tagging', 'is', 'the', 'process', 'of', 'determining', 'the', 'part', 'of', 'speech', 'of', 'a', 'particular', 'word', 'or', 'piece', 'of', 'text', 'based', 'on', 'its', 'use', 'and', 'context', 'part', 'of', 'speech', 'identifies', 'make', 'as', 'a', 'verb', 'in', 'i', 'can', 'make', 'a', 'paper', 'plane', 'and', 'as', 'a', 'noun', 'in', 'what', 'make', 'of', 'car', 'do', 'you', 'own', 'word', 'sense', 'disambiguation', 'is', 'the', 'selection', 'of', 'the', 'meaning', 'of', 'a', 'word', 'with', 'multiple', 'meanings', 'through', 'a', 'process', 'of', 'semantic', 'analysis', 'that', 'determine', 'the', 'word', 'that', 'makes', 'the', 'most', 'sense', 'in', 'the', 'given', 'context', 'for', 'example', 'word', 'sense', 'disambiguation', 'helps', 'distinguish', 'the', 'meaning', 'of', 'the', 'verb', 'in', 'make', 'the', 'grade', 'achieve', 'make', 'a', 'bet', 'place', 'named', 'entity', 'recognition', 'or', 'nem', 'identifies', 'words', 'or', 'phrases', 'as', 'useful', 'entities', 'nem', 'identifies', 'kentucky', 'as', 'a', 'location', 'or', 'fred', 'as', 'a', 'man', 'name', 'resolution', 'is', 'the', 'task', 'of', 'identifying', 'if', 'and', 'when', 'two', 'words', 'refer', 'to', 'the', 'same', 'entity', 'the', 'most', 'common', 'example', 'is', 'determining', 'the', 'person', 'or', 'object', 'to', 'which', 'a', 'certain', 'pronoun', 'refers', 'she', 'mary', 'but', 'it', 'can', 'also', 'involve', 'identifying', 'a', 'metaphor', 'or', 'an', 'idiom', 'in', 'the', 'text', 'an', 'instance', 'in', 'which', 'is', 'an', 'animal', 'but', 'a', 'large', 'hairy', 'person', 'sentiment', 'analysis', 'attempts', 'to', 'extract', 'subjective', 'emotions', 'sarcasm', 'confusion', 'text', 'natural', 'language', 'generation', 'is', 'sometimes', 'described', 'as', 'the', 'opposite', 'of', 'speech', 'recognition', 'or', 'it', 'the', 'task', 'of', 'putting', 'structured', 'information', 'into', 'human', 'language', 'natural', 'language', 'processing', 'is', 'the', 'driving', 'force', 'behind', 'machine', 'intelligence', 'in', 'many', 'modern', 'applications', 'here', 'are', 'a', 'few', 'examples', 'spam', 'detection', 'you', 'may', 'not', 'think', 'of', 'spam', 'detection', 'as', 'an', 'nlp', 'solution', 'but', 'the', 'best', 'spam', 'detection', 'technologies', 'use', 'nlp', 'text', 'classification', 'capabilities', 'to', 'scan', 'emails', 'for', 'language', 'that', 'often', 'indicates', 'spam', 'or', 'phishing', 'these', 'indicators', 'can', 'include', 'overuse', 'of', 'financial', 'terms', 'characteristic', 'bad', 'grammar', 'threatening', 'language', 'inappropriate', 'urgency', 'misspelled', 'company', 'names', 'and', 'more', 'spam', 'detection', 'is', 'one', 'of', 'a', 'handful', 'of', 'nlp', 'problems', 'that', 'experts', 'consider', 'solved', 'although', 'you', 'may', 'argue', 'that', 'this', 'doesn', 't', 'match', 'your', 'email', 'experience', 'machine', 'translation', 'google', 'translate', 'is', 'an', 'example', 'of', 'widely', 'available', 'nlp', 'technology', 'at', 'work', 'truly', 'useful', 'machine', 'translation', 'involves', 'more', 'than', 'replacing', 'words', 'in', 'one', 'language', 'with', 'words', 'of', 'another', 'effective', 'translation', 'has', 'to', 'capture', 'accurately', 'the', 'meaning', 'and', 'tone', 'of', 'the', 'input', 'language', 'and', 'translate', 'it', 'to', 'text', 'with', 'the', 'same', 'meaning', 'and', 'desired', 'impact', 'in', 'the', 'output', 'language', 'machine', 'translation', 'tools', 'are', 'making', 'good', 'progress', 'in', 'terms', 'of', 'accuracy', 'a', 'great', 'way', 'to', 'test', 'any', 'machine', 'translation', 'tool', 'is', 'to', 'translate', 'text', 'to', 'one', 'language', 'and', 'then', 'back', 'to', 'the', 'original', 'an', 'classic', 'example', 'not', 'long', 'ago', 'translating', 'the', 'spirit', 'is', 'willing', 'but', 'the', 'flesh', 'is', 'weak', 'from', 'english', 'to', 'russian', 'and', 'back', 'yielded', 'the', 'vodka', 'is', 'good', 'but', 'the', 'meat', 'is', 'today', 'the', 'result', 'is', 'the', 'spirit', 'desires', 'but', 'the', 'flesh', 'is', 'weak', 'which', 'isn', 't', 'perfect', 'but', 'inspires', 'much', 'more', 'confidence', 'in', 'the', 'translation', 'virtual', 'agents', 'and', 'chatbots', 'virtual', 'agents', 'such', 'as', 'apple', 'siri', 'and', 'amazon', 'alexa', 'use', 'speech', 'recognition', 'to', 'recognize', 'patterns', 'in', 'voice', 'commands', 'and', 'natural', 'language', 'generation', 'to', 'respond', 'with', 'appropriate', 'action', 'or', 'helpful', 'comments', 'chatbots', 'perform', 'the', 'same', 'magic', 'in', 'response', 'to', 'typed', 'text', 'entries', 'the', 'best', 'of', 'these', 'also', 'learn', 'to', 'recognize', 'contextual', 'clues', 'about', 'human', 'requests', 'and', 'use', 'them', 'to', 'provide', 'even', 'better', 'responses', 'or', 'options', 'over', 'time', 'the', 'next', 'enhancement', 'for', 'these', 'applications', 'is', 'question', 'answering', 'the', 'ability', 'to', 'respond', 'to', 'our', 'or', 'relevant', 'and', 'helpful', 'answers', 'in', 'their', 'own', 'words', 'social', 'media', 'sentiment', 'analysis', 'nlp', 'has', 'become', 'an', 'essential', 'business', 'tool', 'for', 'uncovering', 'hidden', 'data', 'insights', 'from', 'social', 'media', 'channels', 'sentiment', 'analysis', 'can', 'analyze', 'language', 'used', 'in', 'social', 'media', 'posts', 'responses', 'reviews', 'and', 'more', 'to', 'extract', 'attitudes', 'and', 'emotions', 'in', 'response', 'to', 'products', 'promotions', 'and', 'companies', 'can', 'use', 'in', 'product', 'designs', 'advertising', 'campaigns', 'and', 'more', 'text', 'summarization', 'text', 'summarization', 'uses', 'nlp', 'techniques', 'to', 'digest', 'huge', 'volumes', 'of', 'digital', 'text', 'and', 'create', 'summaries', 'and', 'synopses', 'for', 'indexes', 'research', 'databases', 'or', 'busy', 'readers', 'who', 'do', 'have', 'time', 'to', 'read', 'full', 'text', 'the', 'best', 'text', 'summarization', 'applications', 'use', 'semantic', 'reasoning', 'and', 'natural', 'language', 'generation', 'nlg', 'to', 'add', 'useful', 'context', 'and', 'conclusions', 'to', 'summaries']\n",
      "Total words in corpus are:  842\n",
      "\n",
      "No of occurrences of Speech:  8\n",
      "No of occurrences of Recognition :  6\n",
      "\n",
      "No of occurrences of Spam:  5\n",
      "No of occurrences of Detection :  4\n",
      "\n",
      "No of occurrences of Machine:  5\n",
      "No of occurrences of Translation :  6\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "f = open('article.txt', encoding=\"utf8\")\n",
    "raw = f.read()\n",
    "words = nltk.word_tokenize(raw)\n",
    "words=[word.lower() for word in words if word.isalpha()]\n",
    "print(words)\n",
    "\n",
    "#to count occurrences of specific words.\n",
    "count1=0\n",
    "count2=0\n",
    "\n",
    "count3=0\n",
    "count4=0\n",
    "\n",
    "count5=0\n",
    "count6=0\n",
    "\n",
    "print(\"Total words in corpus are: \",len(words))\n",
    "\n",
    "#to find collocation for speech & recognition\n",
    "for i in words:\n",
    "    if i.lower()=='speech':\n",
    "        count1=count1+1\n",
    "\n",
    "for i in words:\n",
    "    if i.lower()=='recognition':\n",
    "        count2=count2+1\n",
    "\n",
    "print(\"\\nNo of occurrences of Speech: \", count1)\n",
    "print(\"No of occurrences of Recognition : \", count2)\n",
    "\n",
    "#to find collocation for spam & detection\n",
    "for i in words:\n",
    "    if i.lower()=='spam':\n",
    "        count3=count3+1\n",
    "\n",
    "for i in words:\n",
    "    if i.lower()=='detection':\n",
    "        count4=count4+1\n",
    "\n",
    "print(\"\\nNo of occurrences of Spam: \", count3)\n",
    "print(\"No of occurrences of Detection : \", count4)\n",
    "\n",
    "#to find collocation for machine & translation\n",
    "for i in words:\n",
    "    if i.lower()=='machine':\n",
    "        count5=count5+1\n",
    "\n",
    "for i in words:\n",
    "    if i.lower()=='translation':\n",
    "        count6=count6+1\n",
    "\n",
    "print(\"\\nNo of occurrences of Machine: \", count5)\n",
    "print(\"No of occurrences of Translation : \", count6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53befbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object bigrams at 0x000001895C4B5B60>\n",
      "('human', 'language') 3\n",
      "('language', 'is') 1\n",
      "('is', 'filled') 1\n",
      "('filled', 'with') 1\n",
      "('with', 'ambiguities') 1\n",
      "('ambiguities', 'that') 1\n",
      "('that', 'make') 1\n",
      "('make', 'it') 1\n",
      "('it', 'incredibly') 1\n",
      "('incredibly', 'difficult') 1\n",
      "('difficult', 'to') 1\n",
      "('to', 'write') 1\n",
      "('write', 'software') 1\n",
      "('software', 'that') 1\n",
      "('that', 'accurately') 1\n",
      "('accurately', 'determines') 1\n",
      "('determines', 'the') 1\n",
      "('the', 'intended') 1\n",
      "('intended', 'meaning') 1\n",
      "('meaning', 'of') 3\n",
      "('of', 'text') 2\n",
      "('text', 'or') 1\n",
      "('or', 'voice') 1\n",
      "('voice', 'data') 3\n",
      "('data', 'homonyms') 1\n",
      "('homonyms', 'homophones') 1\n",
      "('homophones', 'sarcasm') 1\n",
      "('sarcasm', 'idioms') 1\n",
      "('idioms', 'metaphors') 1\n",
      "('metaphors', 'grammar') 1\n",
      "('grammar', 'and') 1\n",
      "('and', 'usage') 1\n",
      "('usage', 'exceptions') 1\n",
      "('exceptions', 'variations') 1\n",
      "('variations', 'in') 1\n",
      "('in', 'sentence') 1\n",
      "('sentence', 'just') 1\n",
      "('just', 'a') 1\n",
      "('a', 'few') 2\n",
      "('few', 'of') 1\n",
      "('of', 'the') 4\n",
      "('the', 'irregularities') 1\n",
      "('irregularities', 'of') 1\n",
      "('of', 'human') 1\n",
      "('language', 'that') 2\n",
      "('that', 'take') 1\n",
      "('take', 'humans') 1\n",
      "('humans', 'years') 1\n",
      "('years', 'to') 1\n",
      "('to', 'learn') 1\n",
      "('learn', 'but') 1\n",
      "('but', 'that') 1\n",
      "('that', 'programmers') 1\n",
      "('programmers', 'must') 1\n",
      "('must', 'teach') 1\n",
      "('teach', 'natural') 1\n",
      "('natural', 'applications') 1\n",
      "('applications', 'to') 1\n",
      "('to', 'recognize') 3\n",
      "('recognize', 'and') 1\n",
      "('and', 'understand') 1\n",
      "('understand', 'accurately') 1\n",
      "('accurately', 'from') 1\n",
      "('from', 'the') 1\n",
      "('the', 'start') 1\n",
      "('start', 'if') 1\n",
      "('if', 'those') 1\n",
      "('those', 'applications') 1\n",
      "('applications', 'are') 1\n",
      "('are', 'going') 1\n",
      "('going', 'to') 1\n",
      "('to', 'be') 1\n",
      "('be', 'useful') 1\n",
      "('useful', 'several') 1\n",
      "('several', 'nlp') 1\n",
      "('nlp', 'tasks') 1\n",
      "('tasks', 'break') 1\n",
      "('break', 'down') 1\n",
      "('down', 'human') 1\n",
      "('human', 'text') 1\n",
      "('text', 'and') 2\n",
      "('and', 'voice') 1\n",
      "('data', 'in') 1\n",
      "('in', 'ways') 1\n",
      "('ways', 'that') 1\n",
      "('that', 'help') 1\n",
      "('help', 'the') 1\n",
      "('the', 'computer') 1\n",
      "('computer', 'make') 1\n",
      "('make', 'sense') 1\n",
      "('sense', 'of') 1\n",
      "('of', 'what') 1\n",
      "('what', 'it') 1\n",
      "('it', 'ingesting') 1\n",
      "('ingesting', 'some') 1\n",
      "('some', 'of') 1\n",
      "('of', 'these') 2\n",
      "('these', 'tasks') 1\n",
      "('tasks', 'include') 1\n",
      "('include', 'the') 1\n",
      "('the', 'following') 1\n",
      "('following', 'speech') 1\n",
      "('speech', 'recognition') 5\n",
      "('recognition', 'also') 1\n",
      "('also', 'called') 2\n",
      "('called', 'is') 1\n",
      "('is', 'the') 7\n",
      "('the', 'task') 3\n",
      "('task', 'of') 3\n",
      "('of', 'reliably') 1\n",
      "('reliably', 'converting') 1\n",
      "('converting', 'voice') 1\n",
      "('data', 'into') 1\n",
      "('into', 'text') 1\n",
      "('text', 'data') 1\n",
      "('data', 'speech') 1\n",
      "('recognition', 'is') 1\n",
      "('is', 'required') 1\n",
      "('required', 'for') 1\n",
      "('for', 'any') 1\n",
      "('any', 'application') 1\n",
      "('application', 'that') 1\n",
      "('that', 'follows') 1\n",
      "('follows', 'voice') 1\n",
      "('voice', 'commands') 2\n",
      "('commands', 'or') 1\n",
      "('or', 'answers') 1\n",
      "('answers', 'spoken') 1\n",
      "('spoken', 'questions') 1\n",
      "('questions', 'what') 1\n",
      "('what', 'makes') 1\n",
      "('makes', 'speech') 1\n",
      "('recognition', 'especially') 1\n",
      "('especially', 'challenging') 1\n",
      "('challenging', 'is') 1\n",
      "('the', 'way') 1\n",
      "('way', 'people') 1\n",
      "('people', 'slurring') 1\n",
      "('slurring', 'words') 1\n",
      "('words', 'together') 1\n",
      "('together', 'with') 1\n",
      "('with', 'varying') 1\n",
      "('varying', 'emphasis') 1\n",
      "('emphasis', 'and') 1\n",
      "('and', 'intonation') 1\n",
      "('intonation', 'in') 1\n",
      "('in', 'different') 1\n",
      "('different', 'accents') 1\n",
      "('accents', 'and') 1\n",
      "('and', 'often') 1\n",
      "('often', 'using') 1\n",
      "('using', 'incorrect') 1\n",
      "('incorrect', 'grammar') 1\n",
      "('grammar', 'part') 1\n",
      "('part', 'of') 3\n",
      "('of', 'speech') 4\n",
      "('speech', 'tagging') 1\n",
      "('tagging', 'also') 1\n",
      "('called', 'grammatical') 1\n",
      "('grammatical', 'tagging') 1\n",
      "('tagging', 'is') 1\n",
      "('the', 'process') 1\n",
      "('process', 'of') 2\n",
      "('of', 'determining') 1\n",
      "('determining', 'the') 2\n",
      "('the', 'part') 1\n",
      "('speech', 'of') 1\n",
      "('of', 'a') 3\n",
      "('a', 'particular') 1\n",
      "('particular', 'word') 1\n",
      "('word', 'or') 1\n",
      "('or', 'piece') 1\n",
      "('piece', 'of') 1\n",
      "('text', 'based') 1\n",
      "('based', 'on') 1\n",
      "('on', 'its') 1\n",
      "('its', 'use') 1\n",
      "('use', 'and') 1\n",
      "('and', 'context') 1\n",
      "('context', 'part') 1\n",
      "('speech', 'identifies') 1\n",
      "('identifies', 'make') 1\n",
      "('make', 'as') 1\n",
      "('as', 'a') 4\n",
      "('a', 'verb') 1\n",
      "('verb', 'in') 2\n",
      "('in', 'i') 1\n",
      "('i', 'can') 1\n",
      "('can', 'make') 1\n",
      "('make', 'a') 2\n",
      "('a', 'paper') 1\n",
      "('paper', 'plane') 1\n",
      "('plane', 'and') 1\n",
      "('and', 'as') 1\n",
      "('a', 'noun') 1\n",
      "('noun', 'in') 1\n",
      "('in', 'what') 1\n",
      "('what', 'make') 1\n",
      "('make', 'of') 1\n",
      "('of', 'car') 1\n",
      "('car', 'do') 1\n",
      "('do', 'you') 1\n",
      "('you', 'own') 1\n",
      "('own', 'word') 1\n",
      "('word', 'sense') 2\n",
      "('sense', 'disambiguation') 2\n",
      "('disambiguation', 'is') 1\n",
      "('the', 'selection') 1\n",
      "('selection', 'of') 1\n",
      "('the', 'meaning') 3\n",
      "('a', 'word') 1\n",
      "('word', 'with') 1\n",
      "('with', 'multiple') 1\n",
      "('multiple', 'meanings') 1\n",
      "('meanings', 'through') 1\n",
      "('through', 'a') 1\n",
      "('a', 'process') 1\n",
      "('of', 'semantic') 1\n",
      "('semantic', 'analysis') 1\n",
      "('analysis', 'that') 1\n",
      "('that', 'determine') 1\n",
      "('determine', 'the') 1\n",
      "('the', 'word') 1\n",
      "('word', 'that') 1\n",
      "('that', 'makes') 1\n",
      "('makes', 'the') 1\n",
      "('the', 'most') 2\n",
      "('most', 'sense') 1\n",
      "('sense', 'in') 1\n",
      "('in', 'the') 4\n",
      "('the', 'given') 1\n",
      "('given', 'context') 1\n",
      "('context', 'for') 1\n",
      "('for', 'example') 1\n",
      "('example', 'word') 1\n",
      "('disambiguation', 'helps') 1\n",
      "('helps', 'distinguish') 1\n",
      "('distinguish', 'the') 1\n",
      "('the', 'verb') 1\n",
      "('in', 'make') 1\n",
      "('make', 'the') 1\n",
      "('the', 'grade') 1\n",
      "('grade', 'achieve') 1\n",
      "('achieve', 'make') 1\n",
      "('a', 'bet') 1\n",
      "('bet', 'place') 1\n",
      "('place', 'named') 1\n",
      "('named', 'entity') 1\n",
      "('entity', 'recognition') 1\n",
      "('recognition', 'or') 2\n",
      "('or', 'nem') 1\n",
      "('nem', 'identifies') 2\n",
      "('identifies', 'words') 1\n",
      "('words', 'or') 1\n",
      "('or', 'phrases') 1\n",
      "('phrases', 'as') 1\n",
      "('as', 'useful') 1\n",
      "('useful', 'entities') 1\n",
      "('entities', 'nem') 1\n",
      "('identifies', 'kentucky') 1\n",
      "('kentucky', 'as') 1\n",
      "('a', 'location') 1\n",
      "('location', 'or') 1\n",
      "('or', 'fred') 1\n",
      "('fred', 'as') 1\n",
      "('a', 'man') 1\n",
      "('man', 'name') 1\n",
      "('name', 'resolution') 1\n",
      "('resolution', 'is') 1\n",
      "('of', 'identifying') 1\n",
      "('identifying', 'if') 1\n",
      "('if', 'and') 1\n",
      "('and', 'when') 1\n",
      "('when', 'two') 1\n",
      "('two', 'words') 1\n",
      "('words', 'refer') 1\n",
      "('refer', 'to') 1\n",
      "('to', 'the') 2\n",
      "('the', 'same') 3\n",
      "('same', 'entity') 1\n",
      "('entity', 'the') 1\n",
      "('most', 'common') 1\n",
      "('common', 'example') 1\n",
      "('example', 'is') 1\n",
      "('is', 'determining') 1\n",
      "('the', 'person') 1\n",
      "('person', 'or') 1\n",
      "('or', 'object') 1\n",
      "('object', 'to') 1\n",
      "('to', 'which') 1\n",
      "('which', 'a') 1\n",
      "('a', 'certain') 1\n",
      "('certain', 'pronoun') 1\n",
      "('pronoun', 'refers') 1\n",
      "('refers', 'she') 1\n",
      "('she', 'mary') 1\n",
      "('mary', 'but') 1\n",
      "('but', 'it') 1\n",
      "('it', 'can') 1\n",
      "('can', 'also') 1\n",
      "('also', 'involve') 1\n",
      "('involve', 'identifying') 1\n",
      "('identifying', 'a') 1\n",
      "('a', 'metaphor') 1\n",
      "('metaphor', 'or') 1\n",
      "('or', 'an') 1\n",
      "('an', 'idiom') 1\n",
      "('idiom', 'in') 1\n",
      "('the', 'text') 1\n",
      "('text', 'an') 1\n",
      "('an', 'instance') 1\n",
      "('instance', 'in') 1\n",
      "('in', 'which') 1\n",
      "('which', 'is') 1\n",
      "('is', 'an') 2\n",
      "('an', 'animal') 1\n",
      "('animal', 'but') 1\n",
      "('but', 'a') 1\n",
      "('a', 'large') 1\n",
      "('large', 'hairy') 1\n",
      "('hairy', 'person') 1\n",
      "('person', 'sentiment') 1\n",
      "('sentiment', 'analysis') 3\n",
      "('analysis', 'attempts') 1\n",
      "('attempts', 'to') 1\n",
      "('to', 'extract') 2\n",
      "('extract', 'subjective') 1\n",
      "('subjective', 'emotions') 1\n",
      "('emotions', 'sarcasm') 1\n",
      "('sarcasm', 'confusion') 1\n",
      "('confusion', 'text') 1\n",
      "('text', 'natural') 1\n",
      "('natural', 'language') 4\n",
      "('language', 'generation') 3\n",
      "('generation', 'is') 1\n",
      "('is', 'sometimes') 1\n",
      "('sometimes', 'described') 1\n",
      "('described', 'as') 1\n",
      "('as', 'the') 1\n",
      "('the', 'opposite') 1\n",
      "('opposite', 'of') 1\n",
      "('or', 'it') 1\n",
      "('it', 'the') 1\n",
      "('of', 'putting') 1\n",
      "('putting', 'structured') 1\n",
      "('structured', 'information') 1\n",
      "('information', 'into') 1\n",
      "('into', 'human') 1\n",
      "('language', 'natural') 1\n",
      "('language', 'processing') 1\n",
      "('processing', 'is') 1\n",
      "('the', 'driving') 1\n",
      "('driving', 'force') 1\n",
      "('force', 'behind') 1\n",
      "('behind', 'machine') 1\n",
      "('machine', 'intelligence') 1\n",
      "('intelligence', 'in') 1\n",
      "('in', 'many') 1\n",
      "('many', 'modern') 1\n",
      "('modern', 'applications') 1\n",
      "('applications', 'here') 1\n",
      "('here', 'are') 1\n",
      "('are', 'a') 1\n",
      "('few', 'examples') 1\n",
      "('examples', 'spam') 1\n",
      "('spam', 'detection') 4\n",
      "('detection', 'you') 1\n",
      "('you', 'may') 2\n",
      "('may', 'not') 1\n",
      "('not', 'think') 1\n",
      "('think', 'of') 1\n",
      "('of', 'spam') 1\n",
      "('detection', 'as') 1\n",
      "('as', 'an') 1\n",
      "('an', 'nlp') 1\n",
      "('nlp', 'solution') 1\n",
      "('solution', 'but') 1\n",
      "('but', 'the') 4\n",
      "('the', 'best') 3\n",
      "('best', 'spam') 1\n",
      "('detection', 'technologies') 1\n",
      "('technologies', 'use') 1\n",
      "('use', 'nlp') 1\n",
      "('nlp', 'text') 1\n",
      "('text', 'classification') 1\n",
      "('classification', 'capabilities') 1\n",
      "('capabilities', 'to') 1\n",
      "('to', 'scan') 1\n",
      "('scan', 'emails') 1\n",
      "('emails', 'for') 1\n",
      "('for', 'language') 1\n",
      "('that', 'often') 1\n",
      "('often', 'indicates') 1\n",
      "('indicates', 'spam') 1\n",
      "('spam', 'or') 1\n",
      "('or', 'phishing') 1\n",
      "('phishing', 'these') 1\n",
      "('these', 'indicators') 1\n",
      "('indicators', 'can') 1\n",
      "('can', 'include') 1\n",
      "('include', 'overuse') 1\n",
      "('overuse', 'of') 1\n",
      "('of', 'financial') 1\n",
      "('financial', 'terms') 1\n",
      "('terms', 'characteristic') 1\n",
      "('characteristic', 'bad') 1\n",
      "('bad', 'grammar') 1\n",
      "('grammar', 'threatening') 1\n",
      "('threatening', 'language') 1\n",
      "('language', 'inappropriate') 1\n",
      "('inappropriate', 'urgency') 1\n",
      "('urgency', 'misspelled') 1\n",
      "('misspelled', 'company') 1\n",
      "('company', 'names') 1\n",
      "('names', 'and') 1\n",
      "('and', 'more') 3\n",
      "('more', 'spam') 1\n",
      "('detection', 'is') 1\n",
      "('is', 'one') 1\n",
      "('one', 'of') 1\n",
      "('a', 'handful') 1\n",
      "('handful', 'of') 1\n",
      "('of', 'nlp') 1\n",
      "('nlp', 'problems') 1\n",
      "('problems', 'that') 1\n",
      "('that', 'experts') 1\n",
      "('experts', 'consider') 1\n",
      "('consider', 'solved') 1\n",
      "('solved', 'although') 1\n",
      "('although', 'you') 1\n",
      "('may', 'argue') 1\n",
      "('argue', 'that') 1\n",
      "('that', 'this') 1\n",
      "('this', 'doesn') 1\n",
      "('doesn', 't') 1\n",
      "('t', 'match') 1\n",
      "('match', 'your') 1\n",
      "('your', 'email') 1\n",
      "('email', 'experience') 1\n",
      "('experience', 'machine') 1\n",
      "('machine', 'translation') 4\n",
      "('translation', 'google') 1\n",
      "('google', 'translate') 1\n",
      "('translate', 'is') 1\n",
      "('an', 'example') 1\n",
      "('example', 'of') 1\n",
      "('of', 'widely') 1\n",
      "('widely', 'available') 1\n",
      "('available', 'nlp') 1\n",
      "('nlp', 'technology') 1\n",
      "('technology', 'at') 1\n",
      "('at', 'work') 1\n",
      "('work', 'truly') 1\n",
      "('truly', 'useful') 1\n",
      "('useful', 'machine') 1\n",
      "('translation', 'involves') 1\n",
      "('involves', 'more') 1\n",
      "('more', 'than') 1\n",
      "('than', 'replacing') 1\n",
      "('replacing', 'words') 1\n",
      "('words', 'in') 1\n",
      "('in', 'one') 1\n",
      "('one', 'language') 2\n",
      "('language', 'with') 1\n",
      "('with', 'words') 1\n",
      "('words', 'of') 1\n",
      "('of', 'another') 1\n",
      "('another', 'effective') 1\n",
      "('effective', 'translation') 1\n",
      "('translation', 'has') 1\n",
      "('has', 'to') 1\n",
      "('to', 'capture') 1\n",
      "('capture', 'accurately') 1\n",
      "('accurately', 'the') 1\n",
      "('meaning', 'and') 2\n",
      "('and', 'tone') 1\n",
      "('tone', 'of') 1\n",
      "('the', 'input') 1\n",
      "('input', 'language') 1\n",
      "('language', 'and') 2\n",
      "('and', 'translate') 1\n",
      "('translate', 'it') 1\n",
      "('it', 'to') 1\n",
      "('to', 'text') 1\n",
      "('text', 'with') 1\n",
      "('with', 'the') 1\n",
      "('same', 'meaning') 1\n",
      "('and', 'desired') 1\n",
      "('desired', 'impact') 1\n",
      "('impact', 'in') 1\n",
      "('the', 'output') 1\n",
      "('output', 'language') 1\n",
      "('language', 'machine') 1\n",
      "('translation', 'tools') 1\n",
      "('tools', 'are') 1\n",
      "('are', 'making') 1\n",
      "('making', 'good') 1\n",
      "('good', 'progress') 1\n",
      "('progress', 'in') 1\n",
      "('in', 'terms') 1\n",
      "('terms', 'of') 1\n",
      "('of', 'accuracy') 1\n",
      "('accuracy', 'a') 1\n",
      "('a', 'great') 1\n",
      "('great', 'way') 1\n",
      "('way', 'to') 1\n",
      "('to', 'test') 1\n",
      "('test', 'any') 1\n",
      "('any', 'machine') 1\n",
      "('translation', 'tool') 1\n",
      "('tool', 'is') 1\n",
      "('is', 'to') 1\n",
      "('to', 'translate') 1\n",
      "('translate', 'text') 1\n",
      "('text', 'to') 1\n",
      "('to', 'one') 1\n",
      "('and', 'then') 1\n",
      "('then', 'back') 1\n",
      "('back', 'to') 1\n",
      "('the', 'original') 1\n",
      "('original', 'an') 1\n",
      "('an', 'classic') 1\n",
      "('classic', 'example') 1\n",
      "('example', 'not') 1\n",
      "('not', 'long') 1\n",
      "('long', 'ago') 1\n",
      "('ago', 'translating') 1\n",
      "('translating', 'the') 1\n",
      "('the', 'spirit') 2\n",
      "('spirit', 'is') 1\n",
      "('is', 'willing') 1\n",
      "('willing', 'but') 1\n",
      "('the', 'flesh') 2\n",
      "('flesh', 'is') 2\n",
      "('is', 'weak') 2\n",
      "('weak', 'from') 1\n",
      "('from', 'english') 1\n",
      "('english', 'to') 1\n",
      "('to', 'russian') 1\n",
      "('russian', 'and') 1\n",
      "('and', 'back') 1\n",
      "('back', 'yielded') 1\n",
      "('yielded', 'the') 1\n",
      "('the', 'vodka') 1\n",
      "('vodka', 'is') 1\n",
      "('is', 'good') 1\n",
      "('good', 'but') 1\n",
      "('the', 'meat') 1\n",
      "('meat', 'is') 1\n",
      "('is', 'today') 1\n",
      "('today', 'the') 1\n",
      "('the', 'result') 1\n",
      "('result', 'is') 1\n",
      "('spirit', 'desires') 1\n",
      "('desires', 'but') 1\n",
      "('weak', 'which') 1\n",
      "('which', 'isn') 1\n",
      "('isn', 't') 1\n",
      "('t', 'perfect') 1\n",
      "('perfect', 'but') 1\n",
      "('but', 'inspires') 1\n",
      "('inspires', 'much') 1\n",
      "('much', 'more') 1\n",
      "('more', 'confidence') 1\n",
      "('confidence', 'in') 1\n",
      "('the', 'translation') 1\n",
      "('translation', 'virtual') 1\n",
      "('virtual', 'agents') 2\n",
      "('agents', 'and') 1\n",
      "('and', 'chatbots') 1\n",
      "('chatbots', 'virtual') 1\n",
      "('agents', 'such') 1\n",
      "('such', 'as') 1\n",
      "('as', 'apple') 1\n",
      "('apple', 'siri') 1\n",
      "('siri', 'and') 1\n",
      "('and', 'amazon') 1\n",
      "('amazon', 'alexa') 1\n",
      "('alexa', 'use') 1\n",
      "('use', 'speech') 1\n",
      "('recognition', 'to') 1\n",
      "('recognize', 'patterns') 1\n",
      "('patterns', 'in') 1\n",
      "('in', 'voice') 1\n",
      "('commands', 'and') 1\n",
      "('and', 'natural') 2\n",
      "('generation', 'to') 1\n",
      "('to', 'respond') 2\n",
      "('respond', 'with') 1\n",
      "('with', 'appropriate') 1\n",
      "('appropriate', 'action') 1\n",
      "('action', 'or') 1\n",
      "('or', 'helpful') 1\n",
      "('helpful', 'comments') 1\n",
      "('comments', 'chatbots') 1\n",
      "('chatbots', 'perform') 1\n",
      "('perform', 'the') 1\n",
      "('same', 'magic') 1\n",
      "('magic', 'in') 1\n",
      "('in', 'response') 2\n",
      "('response', 'to') 2\n",
      "('to', 'typed') 1\n",
      "('typed', 'text') 1\n",
      "('text', 'entries') 1\n",
      "('entries', 'the') 1\n",
      "('best', 'of') 1\n",
      "('these', 'also') 1\n",
      "('also', 'learn') 1\n",
      "('learn', 'to') 1\n",
      "('recognize', 'contextual') 1\n",
      "('contextual', 'clues') 1\n",
      "('clues', 'about') 1\n",
      "('about', 'human') 1\n",
      "('human', 'requests') 1\n",
      "('requests', 'and') 1\n",
      "('and', 'use') 1\n",
      "('use', 'them') 1\n",
      "('them', 'to') 1\n",
      "('to', 'provide') 1\n",
      "('provide', 'even') 1\n",
      "('even', 'better') 1\n",
      "('better', 'responses') 1\n",
      "('responses', 'or') 1\n",
      "('or', 'options') 1\n",
      "('options', 'over') 1\n",
      "('over', 'time') 1\n",
      "('time', 'the') 1\n",
      "('the', 'next') 1\n",
      "('next', 'enhancement') 1\n",
      "('enhancement', 'for') 1\n",
      "('for', 'these') 1\n",
      "('these', 'applications') 1\n",
      "('applications', 'is') 1\n",
      "('is', 'question') 1\n",
      "('question', 'answering') 1\n",
      "('answering', 'the') 1\n",
      "('the', 'ability') 1\n",
      "('ability', 'to') 1\n",
      "('respond', 'to') 1\n",
      "('to', 'our') 1\n",
      "('our', 'or') 1\n",
      "('or', 'relevant') 1\n",
      "('relevant', 'and') 1\n",
      "('and', 'helpful') 1\n",
      "('helpful', 'answers') 1\n",
      "('answers', 'in') 1\n",
      "('in', 'their') 1\n",
      "('their', 'own') 1\n",
      "('own', 'words') 1\n",
      "('words', 'social') 1\n",
      "('social', 'media') 3\n",
      "('media', 'sentiment') 1\n",
      "('analysis', 'nlp') 1\n",
      "('nlp', 'has') 1\n",
      "('has', 'become') 1\n",
      "('become', 'an') 1\n",
      "('an', 'essential') 1\n",
      "('essential', 'business') 1\n",
      "('business', 'tool') 1\n",
      "('tool', 'for') 1\n",
      "('for', 'uncovering') 1\n",
      "('uncovering', 'hidden') 1\n",
      "('hidden', 'data') 1\n",
      "('data', 'insights') 1\n",
      "('insights', 'from') 1\n",
      "('from', 'social') 1\n",
      "('media', 'channels') 1\n",
      "('channels', 'sentiment') 1\n",
      "('analysis', 'can') 1\n",
      "('can', 'analyze') 1\n",
      "('analyze', 'language') 1\n",
      "('language', 'used') 1\n",
      "('used', 'in') 1\n",
      "('in', 'social') 1\n",
      "('media', 'posts') 1\n",
      "('posts', 'responses') 1\n",
      "('responses', 'reviews') 1\n",
      "('reviews', 'and') 1\n",
      "('more', 'to') 1\n",
      "('extract', 'attitudes') 1\n",
      "('attitudes', 'and') 1\n",
      "('and', 'emotions') 1\n",
      "('emotions', 'in') 1\n",
      "('to', 'products') 1\n",
      "('products', 'promotions') 1\n",
      "('promotions', 'and') 1\n",
      "('and', 'companies') 1\n",
      "('companies', 'can') 1\n",
      "('can', 'use') 1\n",
      "('use', 'in') 1\n",
      "('in', 'product') 1\n",
      "('product', 'designs') 1\n",
      "('designs', 'advertising') 1\n",
      "('advertising', 'campaigns') 1\n",
      "('campaigns', 'and') 1\n",
      "('more', 'text') 1\n",
      "('text', 'summarization') 3\n",
      "('summarization', 'text') 1\n",
      "('summarization', 'uses') 1\n",
      "('uses', 'nlp') 1\n",
      "('nlp', 'techniques') 1\n",
      "('techniques', 'to') 1\n",
      "('to', 'digest') 1\n",
      "('digest', 'huge') 1\n",
      "('huge', 'volumes') 1\n",
      "('volumes', 'of') 1\n",
      "('of', 'digital') 1\n",
      "('digital', 'text') 1\n",
      "('and', 'create') 1\n",
      "('create', 'summaries') 1\n",
      "('summaries', 'and') 1\n",
      "('and', 'synopses') 1\n",
      "('synopses', 'for') 1\n",
      "('for', 'indexes') 1\n",
      "('indexes', 'research') 1\n",
      "('research', 'databases') 1\n",
      "('databases', 'or') 1\n",
      "('or', 'busy') 1\n",
      "('busy', 'readers') 1\n",
      "('readers', 'who') 1\n",
      "('who', 'do') 1\n",
      "('do', 'have') 1\n",
      "('have', 'time') 1\n",
      "('time', 'to') 1\n",
      "('to', 'read') 1\n",
      "('read', 'full') 1\n",
      "('full', 'text') 1\n",
      "('text', 'the') 1\n",
      "('best', 'text') 1\n",
      "('summarization', 'applications') 1\n",
      "('applications', 'use') 1\n",
      "('use', 'semantic') 1\n",
      "('semantic', 'reasoning') 1\n",
      "('reasoning', 'and') 1\n",
      "('generation', 'nlg') 1\n",
      "('nlg', 'to') 1\n",
      "('to', 'add') 1\n",
      "('add', 'useful') 1\n",
      "('useful', 'context') 1\n",
      "('context', 'and') 1\n",
      "('and', 'conclusions') 1\n",
      "('conclusions', 'to') 1\n",
      "('to', 'summaries') 1\n"
     ]
    }
   ],
   "source": [
    "#Create bigrams\n",
    "from nltk import bigrams\n",
    "bgs = nltk.bigrams(words)\n",
    "print(bgs)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "fdist = nltk.FreqDist(bgs)\n",
    "for k,v in fdist.items():\n",
    "    print (k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db5b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECTED BIGRAMS ARE:\n",
    "(Stop words not removed. Bigrams taken with no stopwords in it)\n",
    "speech recognition- 5\n",
    "spam detection - 4\n",
    "machine translation - 4\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ee2b0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbar=  0.0059382422802850355\n",
      "s2=  0.005902979558905671\n",
      "t value=  2.21716645359012\n",
      "Speech Recognition is not a collocation\n"
     ]
    }
   ],
   "source": [
    "#T test for speech and recognition\n",
    "from math import sqrt\n",
    "\n",
    "p_speech = count1/len(words)\n",
    "p_recognition= count2/len(words)\n",
    "p_speech_recognition= p_speech*p_recognition   \n",
    "\n",
    "xbar=5/len(words)\n",
    "print(\"xbar= \",xbar)\n",
    "\n",
    "s2=xbar*(1-xbar)\n",
    "print(\"s2= \",s2)\n",
    "\n",
    "t=(xbar- p_speech_recognition)/sqrt((s2/len(words)))\n",
    "print(\"t value= \",t)    \n",
    "\n",
    "critical_val=2.576  #for t test\n",
    "\n",
    "if (t < critical_val): \n",
    "    print(\"Speech Recognition is not a collocation\")\n",
    "else:\n",
    "    print(\"Speech Recognition is a collocation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da094641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbar=  0.004750593824228029\n",
      "s2=  0.004728025682545235\n",
      "t value=  1.9928627915692063\n",
      "Spam Detection is not a collocation\n"
     ]
    }
   ],
   "source": [
    "#T test for spam & detection\n",
    "from math import sqrt\n",
    "\n",
    "p_spam = count3/len(words)\n",
    "p_detection= count4/len(words)\n",
    "p_spam_detection= p_spam*p_detection    \n",
    "\n",
    "xbar=4/len(words)\n",
    "print(\"xbar= \",xbar)  \n",
    "\n",
    "s2=xbar*(1-xbar)\n",
    "print(\"s2= \",s2)\n",
    "\n",
    "t=(xbar- p_spam_detection)/sqrt((s2/len(words)))\n",
    "print(\"t value= \",t)      \n",
    "\n",
    "if (t < critical_val): \n",
    "    print(\"Spam Detection is not a collocation\")\n",
    "else:\n",
    "    print(\"Spam Detection is a collocation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "461bd4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbar=  0.004750593824228029\n",
      "s2=  0.004728025682545235\n",
      "t value=  1.9869103937449253\n",
      "machine Detection is not a collocation\n"
     ]
    }
   ],
   "source": [
    "#T test for machine & translation\n",
    "from math import sqrt\n",
    "\n",
    "p_machine = count5/len(words)\n",
    "p_translation= count6/len(words)\n",
    "p_machine_translation= p_machine*p_translation \n",
    "\n",
    "xbar=4/len(words)\n",
    "print(\"xbar= \",xbar)     \n",
    "\n",
    "s2=xbar*(1-xbar)\n",
    "print(\"s2= \",s2)\n",
    "\n",
    "t=(xbar- p_machine_translation)/sqrt((s2/842))\n",
    "print(\"t value= \",t)    \n",
    "\n",
    "if (t < critical_val): \n",
    "    print(\"machine Detection is not a collocation\")\n",
    "else:\n",
    "    print(\"machine Detection is a collocation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
